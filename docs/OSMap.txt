# What?

this text file documents a lot of the design assumptions that are made for QBeOS.
it also describes the output files and their formats produced from the build process step by step.

# QBeOS
A 32 bit OS supports running on IA32 arch processors.

# road map
Highlevel overview of the road map of development for QBeOS
* GDT
* PMM
* VMM
  * Paging
  * Public APIs
* IDT
  * IDT Structures
  * ISRs
* LDT
* TSS
* SIMD
* ACPI
* APIC
* IOAPIC
* LAPIC
* HPET
* APIC-TIMER
* SMP
* Multitasking
* Syscalls
* Userspace
* The fun begin

TODOs - Technical Debt stemming from the fact of how excited I am to go to user mode:
* Implement config for kernel features (Should self test or no fx)
* Refactor testing to be automated with asserts
* Implement EFI loading
* Switch to CMake at some point
* Compile libgcc with no-red-zone and mcmodel=kernel. This is a must in long mode and/or x86_64 modes.


# QBeOS components and dir structure

QBeOS kernel (QBeKern) : /src : c++
QBeOS bootloader (QBeL) : /boot : assembly NASM

QBeOS will only be iso bootable. ISO 9660 will be the first "semi-supported" fs.
This allows 2046 bytes bootloader; a 2kb boot loader to be loaded!! maybe no need for 2 stages?
we will see.

# Bootloader

## List of important assumptions made
* the kernel and bootloader exist both in the root directory. There are no other directories on the CD

## qbeos bootloader
the bootloader in boot directory contains all assembly files required to build the bootloader. NASM is used for this task.
the main file bootloader.asm contains all required files and is the main entry to the bootloader. inside this file, other files
are imported that holds other functionalities.

## qbeos bootloader kernel boot params
qbeos BL passes a specific set of params to the kernel it is booting. these params are organized as the following.
TODO: if a requirement rises that requires this implement it. otherwise delete the TODO.


# Memory Map of the Bootloader + Kernel
Lookup memory_layout.md first.

START            END          SIZE           description
0x00000          0x003ff      1KB            RealMode IVT
0x00400          0x004ff      256B           BIOS Data Area (BDA)
0x00500          0x00d00      2KB            PVD of QBeOS ISO
0x00d00          0x02d00      8KB            Bootloader params area
0x02d00          0x07bff      19.75KB        QBeOS Bootloader (BL) stack
0x07c00          0x083ff      2KB            QBeOS BL
0x08400          0x6ffff      479Kb          QBeOS Kernel
0x70000          0x7ffff      64KB           Memory Layout Table
0x80000          0x100000     512KB          Bios Data <- don't mess with this
0x100000         0x10ffff     64KB           High Memory Area in Real mode
------------------------------  Protected Mode -------------------------------
0x00100000       0x003fffff   2MB            OS Stack(s)
0x00400000       0x004fffff   1MB            GDT table
0x00500000       0x0050ffff   64KB           VMM PDT
0x00510000       0x0090ffff   4MB            VMM PTs
0x00910000       0x0091ffff   64KB           IDT Table
0x00920000       ??????????   0.01% of Mem   Physical Memory tables

# QBeOS Kernel

the output of this module is the KERNEL.IMG binary file.

## Important
.. keep this here. important learning
I have discovered that if I want to write a kernel that is bigger than 400KBs (conventional memory available below 1Mib Boundry)
I need to load it into memory beyond the 1Mib boundry. in real mode, beyond the 1Mib boundry only 64Kbs available so that means
the size of my kernel can't be bigger than 464Kbs. at the time of writing this, my basic, not so good, kernel that only writes
stuff to screen is 1.2Kb. I have naively thought I could trick the BIOS bytes setting the pointer to the buffer where the
kernel is loaded to the 1Mib boundary exactly, hoping the BIOS will be able to do so itself (i.e, access memory beyond 1Mib +
64Kb) but the BIOS was.. well.. smarter or dumber than me.. eventually I researched osdev and found out that BIOS is not reliable in loading
stuff above 1Mib, but I can load below 1Mib and relocate data there.

so taking a pause here to evaluate these two decisions:

* Continue as I am now, and leave this problem for future me.
**Changes:
*** I will restructure the memory layout to load the kernel in a lower address.

** Pros:
*** short - no changes really
*** get to the good stuff (the actual OS things)

** Cons:
*** may struggle when I hit the limits of the 1Mib memory while loading the kernel

* Implement a solution for this.
**Changes:
*** to talk to higher memroy I need to be in protected mode. When I am in protected mode, I will not be able to use BIOS
    Interrupts which means I will not be able to load the kernel while in real mode before jumping to protected mode. That means,
    to load the kernel I will have to jump to protected mode and load the kernel via a driver. this is already smelling like 2
    stage bootloader.

# Virtual Memory management
The essential objective of virtual memory management is to implement how addresses are
translated and memory access control. There are three types of addresses into
memory.
Virtual address(AKA logical address), linear address, physical address.
At the end of the day physical address is the address used to access the memory.
If we have a flat memory model, i.e, GDT: Code Segment == Data Segment == The
whole memory (this is set by having 2 GDT entries spanning the whole
memory limits), then Virtual address is the same as a linear address.
This is because linear address is produced from virtual address by means of
segmentation. The virtual address consists of 16 bit selector and 32 bit offset.
The selectors are selectors into the GDT or LDT depending on the context.
LDT is associated with tasks. When in flat memory model, the selectors
are preloaded during boot after switching to protected mode from real mode.
The physical address is calculated from the linear address via paging. the linear
address is split into 10 10 12 bits. The first 10 bits point into page directory.
it is the index of a page directory entry. A page directory entry then points to
a page table. The second 10 bits point into the index of a page table entry.
A page table entry points to the start of a page in physical memory. the last 12
bits is the index of the byte in the page. That means each page can be 4096 byte
or 4kbs.
Likewise, if paging is disabled then Virtual address maps to linear address via
the GDT and linear address in this case is the same as physical address.

In conclusion, segmentation and paging are two different memory protection modes.
They can be used together or one can be used and not the other. Segemntation can
be used to isolate tasks in a multitasking or multiprocess environments. The
latter is the environment you get when the CPU has multicores. Segmentation is
deprecated so in QBeOS we use a flat memory model. We will only protect kernel
code and data memory space.


Note: All of this information can be found in intel manuals Vol3 Chapter 3.

# QBeOS Memory Management model
Right after the bootloader is done and before jumping to the kernel, the memory
model is flat memory model. i.e, both code and data descriptors in GDT map to
the whole available memory address space.

QBeOS for the time being is 32 bit OS (TODO: Switch to 64 bits)

After booting, QBeOS defines 4 segments in GDT spanning the whole memory, 2 for
kernel code and data, and 2 for user code and data + 1 null descriptor:
index          | Base           | LIMIT         | Description
0              | 0              | 0             | null descriptor
1              | 0x00000000     | 0xFFFFF       | executable kernel code
2              | 0x00000000     | 0xFFFFF       | nonexecutable kernel data
3              | 0x00c00000     | 0xFFFFFF      | user executable
4              | 0x00c00000     | 0xFFFFFF      | user data

The purpose of this segmentation model is just to protect kernel area from user
area. We will rely also on paging to protect kernel and user code from each other as well.
GDT will be used for LDT and TSS as well.

# MemoryManager
the memory manager (Memory:memory.h) is responsible for the physical memory. The memory manager is just that
a memory manager.
Memory is initialized by reading the memory tables placed by the bootloader at 0x70000.
It then splits the memory into physical pages.
Each page will be of size PAGE_SIZE(4k).
Post initialization, Memory marks the pages used by the kernel as reserved.

Memory Public API (Size is in bytes):
AllocPhysicalPage(): searches for the first free page and allocates it. return pointer to base of page
Allocate(size): allocates X + (X + PAGE_SIZE) % PAGE_SIZE pages and returns pointer to first page.
Free(pagePointer): given a page pointer that begins on the page boundary, free the string of pages marked with allocation ID.

# VirtualMemory and virtual memory management
QBeKern will place PDT entries starting address 0x2500000. In 32 bit mode we have 2 levels only (PDT, PT) each is 1024 entries.
each entry is 8 bytes so ideally 16KBs should be sufficient for such tables. However, in 64 bits long mode, we need to expand
this memory requirement to include a max of 5 levels (5 * 1024 * 8 = 40KBs).
Since QBeKern is 32 bits for now, we will stick with only 2 levels of page tables. Once paging is enabled, even the kernel
memory locations will be accessed via MMU.
QBeKern will be a higher half kernel. That means on 32 bits we map the kernel starting address 0xc0000000. For now, the
kernel and all of its everything exist in the lower 8MBs of the kernel.
There will be two stages for paging to avoid issues.
* First 8MBs of virtual address will point to first 8MBs of physical addresses.
* First 8MBs after 0xc0000000 will point to first 8MBs of physical addresses.
* Paging Enabled, jump absolute (jmp <from reg>)
* First 8MBs gets unmapped to zero.
if memory is 4GBs (Max on 32 bits), 1024 PDTEntries with, 1024 PTEntries
every PDTEntry is 32bits and each PTEntry is 32bits
That's PDT Size = 1024 * 32 = 4096 bytes (4kb)

# IDT
I implemented the PMM and was about to implement the VMM and paging but stopped for a second with the question, Assume we have a working VMM
and paging, if a page fault happens (major or minor) how it will be handled? It's through Exceptions, which is part of the IDT. So I decided
okay, maybe its a good idea to implement IDT before VMM and paging. so this section is about IDT symantics and desgin in QBeOS Kern.

Interrupts are signals coming to the CPU instructing it to stop whatever it is doing and service them. Interrupts service 3 purposes:
* informing the kernel there is an Exception that happened (page faults, double faults, general protection fault, etc.)
* informing the kernel there is a hardware that wants to send/recieve data (hardware interrupt generated externally)
* informing the kernel there is a process that requires its attention via system call (software interrupts).

## PIC: Programmable interrupt controller
on x86 architecture the hardware interrupts are handled via an external chip named PIC. this has a layout of a master and slave chip. Each chip
provides 8 interrupts but a total of 15 interrupts can be handled becuase there is one interrupt line to connect the master chip with the slave chip.

## APIC: Advanced programmable interrupt controller
This is the next generation succeeding PIC. This is used for more sophisticated interrupt redirection mechanisms and allows CPUs interrupting each other.
This is a necessity in SMP/SIMD envs.

## IVT
This is the interrupt table that exists in real mode. The BIOS sets this table up. This is a 4 byte per table entry table where each entry has 2 bytes
referencing segment and 2 bytes referencing offset, both mark the address of the routine to run when this interrupt happens. These are the routines that
run when we do for example int 15h in real mode.


# IDT in QBeOS Kern
QBeOS Kern will support PIC and upon discovery of APIC functionalities it will rely on APIC.

## PIC

## ACPI
* first, kernel checks if CPU supports APIC or not. if not rely on PIC.
* if yes, search the ram for the RSDP (Root System Description Pointer).
